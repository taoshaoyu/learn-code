{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can not run\n",
    "# https://zhuanlan.zhihu.com/p/30572900\n",
    "# FIXBUG: what is input_tensor\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST数据集相关的常数。\n",
    "INPUT_NODE = 784      # 输入层的节点数。对于MNIST数据集，这个就等于图片的像素。   \n",
    "OUTPUT_NODE = 10     # 输出层的节点数。这个等于类别的数目。因为在MNIST数据集中\n",
    "                         # 需要区分的是0~9这10个数字，所以这里输出层的节点数为10。\n",
    "\n",
    "# 配置神经网络的参数。\n",
    "LAYER1_NODE = 500   # 隐藏层节点数。这里使用只有一个隐藏层的网络结构作为样例。\n",
    "                        # 这个隐藏层有500个节点。\n",
    "BATCH_SIZE = 100    # 一个训练batch中的训练数据个数。数字越小时，训练过程越接近\n",
    "                        # 随机梯度下降；数字越大时，训练越接近梯度下降。\n",
    "LEARNING_RATE = 0.01           # 学习率。\n",
    "TRAINING_STEPS = 10000              # 训练轮数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x_data, y_data, batch_size):\n",
    "    idxs = np.random.randint(0, len(y_data), batch_size)\n",
    "    y_ret_data=[]\n",
    "    for i in y_data[idxs]:\n",
    "        tmp=np.zeros(10)\n",
    "        tmp[i]=1\n",
    "        y_ret_data.append(tmp)\n",
    "    return x_data[idxs,:,:].reshape(batch_size,28*28), np.array(y_ret_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    # 定义神经网络参数。\n",
    "    weights1 = tf.Variable(\n",
    "    tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    bias1 = tf.Variable(tf.constant(0.0, shape=[LAYER1_NODE]))\n",
    "    weights2 = tf.Variable(\n",
    "    tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    bias2 = tf.Variable(tf.constant(0.0, shape=[OUTPUT_NODE]))\n",
    "\n",
    "# 计算在当前参数下神经网络前向传播的结果。\n",
    "    layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + bias1)\n",
    "    y = tf.matmul(layer1, weights2) + bias2\n",
    "\n",
    "# 定义存储训练轮数的变量。 \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    \n",
    "# 计算交叉熵作为刻画预测值和真实值之间差距的损失函数。\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=y_, logits=y)\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "           \n",
    "    # 使用tf.train.GradientDescentOptimizer优化算法来优化损失函数。注意这里损失\n",
    "    # 函数包含了交叉熵损失和L2正则化损失。\n",
    "    train_op=tf.train.GradientDescentOptimizer(LEARNING_RATE)\\\n",
    "                 .minimize(loss, global_step=global_step)\n",
    "\n",
    "    # 检验神经网络的正确率。\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  \n",
    "    # 初始化会话并开始训练过程。\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "    # 准备验证数据。一般在神经网络的训练过程中会通过验证数据来大致判断停止的\n",
    "    # 条件和评判训练的效果。\n",
    "        validate_feed = {x: mnist.validation.images, \n",
    "                             y_: mnist.validation.labels}\n",
    "\n",
    "    # 准备测试数据。在真实的应用中，这部分数据在训练时是不可见的，这个数据只是作为  \n",
    "    # 模型优劣的最后评价标准。\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}     \n",
    "\n",
    "        # 迭代地训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            # 每1000轮输出一次在验证数据集上的测试结果。\n",
    "            if i % 1000 == 0:\n",
    "                    validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                    print(\"After %d training step(s), validation accuracy \"\n",
    "                         \"using average model is %g \" % (i, validate_acc))\n",
    "            \n",
    "            # 产生这一轮使用的一个batch的训练数据，并运行训练过程。\n",
    "            xs, ys = get_batch(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x: xs, y_: ys})\n",
    "\n",
    "        # 在训练结束之后，在测试数据上检测神经网络模型的最终正确率。\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "    print(\"After %d training step(s), test accuracy using average \"\n",
    "           \"model is %g\" % (TRAINING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None): \n",
    "    # 声明处理MNIST数据集的类，这个类在初始化时会自动下载数据。\n",
    "    train(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [26], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(argv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m): \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 声明处理MNIST数据集的类，这个类在初始化时会自动下载数据。\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnist\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [21], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(mnist)\u001b[0m\n\u001b[1;32m     11\u001b[0m     bias2 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m0.0\u001b[39m, shape\u001b[38;5;241m=\u001b[39m[OUTPUT_NODE]))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 计算在当前参数下神经网络前向传播的结果。\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     layer1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(tf\u001b[38;5;241m.\u001b[39mmatmul(\u001b[43minput_tensor\u001b[49m, weights1) \u001b[38;5;241m+\u001b[39m bias1)\n\u001b[1;32m     15\u001b[0m     y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(layer1, weights2) \u001b[38;5;241m+\u001b[39m bias2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 定义存储训练轮数的变量。 \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
