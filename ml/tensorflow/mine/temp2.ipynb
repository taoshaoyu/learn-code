{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> x\n",
      "[] -> y\n",
      "['x', 'y'] -> MatMul\n",
      "['MatMul'] -> Relu\n",
      "['Relu'] -> Identity\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_func(x, y):\n",
    "  return tf.nn.relu(tf.matmul(x, y))\n",
    "a=my_func.get_concrete_function(tf.random.uniform((3, 3)),tf.random.uniform((3, 3)))\n",
    "for node in a.graph.as_graph_def().node:\n",
    "  print(f'{node.input} -> {node.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> Const\n",
      "['Const'] -> Identity\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_func(x, y):\n",
    "  return x+y\n",
    "a=my_func.get_concrete_function(1,2)\n",
    "for node in a.graph.as_graph_def().node:\n",
    "  print(f'{node.input} -> {node.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> x\n",
      "['x'] -> Relu\n",
      "['Relu'] -> Identity\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def my_func(x):\n",
    "  return tf.nn.relu(x)\n",
    "a=my_func.get_concrete_function(tf.random.uniform((3, 3)))\n",
    "for node in a.graph.as_graph_def().node:\n",
    "  print(f'{node.input} -> {node.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  if tf.reduce_sum(x) > 0:\n",
    "    return x * x\n",
    "  else:\n",
    "    return -x // 2\n",
    "f(tf.constant(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.constant(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.eager.def_function.Function"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.function(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `tf.python.eager.function` not found.\n"
     ]
    }
   ],
   "source": [
    "tensorflow.python.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager.function import Function as F1\n",
    "from tensorflow.python.eager.def_function import function as f2\n",
    "from tensorflow.python.eager.def_function import Function as F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_f2_f=F2(f,\"func_f2\")\n",
    "func_f1_f=F1(f,\"func_f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_f1_f._autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_f2_f._autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.core.framework.node_def_pb2 import NodeDef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.core.framework.node_def_pb2.NodeDef"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] -> Const, opConst\n",
      "[] -> Const_1, opConst\n",
      "['Const', 'Const_1'] -> add, opAddV2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1=tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    a=tf.constant([1,2])\n",
    "    b=tf.constant([1,1])\n",
    "    result=a+b\n",
    "\n",
    "for node in g1.as_graph_def().node:\n",
    "  print(f'{node.input} -> {node.name}, op: {node.op}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Graph"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g1.as_default() as g:\n",
    "    hg=g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1=tf.Graph()\n",
    "with g1.as_default() as dg:\n",
    "    print(g1._nodes_by_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mop_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Creates an `Operation` in this graph. (deprecated arguments)\n",
      "\n",
      "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "\n",
      "This is a low-level interface for creating an `Operation`. Most\n",
      "programs will not call this method directly, and instead use the\n",
      "Python op constructors, such as `tf.constant()`, which add ops to\n",
      "the default graph.\n",
      "\n",
      "Args:\n",
      "  op_type: The `Operation` type to create. This corresponds to the\n",
      "    `OpDef.name` field for the proto that defines the operation.\n",
      "  inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      "  dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      "    tensors that the operation produces.\n",
      "  input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      "    tensors that the operation consumes. By default, uses the base `DType`\n",
      "    of each input in `inputs`. Operations that expect reference-typed inputs\n",
      "    must specify `input_types` explicitly.\n",
      "  name: (Optional.) A string name for the operation. If not specified, a\n",
      "    name is generated based on `op_type`.\n",
      "  attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      "    string) and the value is the respective `attr` attribute of the\n",
      "    `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      "    proto).\n",
      "  op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      "    the operation will have.\n",
      "  compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      "    computed).\n",
      "  compute_device: (Optional.) If True, device functions will be executed to\n",
      "    compute the device property of the Operation.\n",
      "\n",
      "Raises:\n",
      "  TypeError: if any of the inputs is not a `Tensor`.\n",
      "  ValueError: if colocation conflicts with existing device assignment.\n",
      "\n",
      "Returns:\n",
      "  An `Operation` object.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "g.create_op?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce_retracing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_implements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_autograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_relax_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_follow_type_hints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)\n",
      "\n",
      "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_compile)`. They will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "\n",
      "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_relax_shapes)`. They will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\n",
      "`tf.function` constructs a `tf.types.experimental.GenericFunction` that\n",
      "executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "TensorFlow operations in `func`. More information on the topic can be found\n",
      "in [Introduction to Graphs and tf.function]\n",
      "(https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "\n",
      "See [Better Performance with tf.function]\n",
      "(https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "known limitations.\n",
      "\n",
      "Example usage:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x, y):\n",
      "...   return x ** 2 + y\n",
      ">>> x = tf.constant([2, 3])\n",
      ">>> y = tf.constant([3, -2])\n",
      ">>> f(x, y)\n",
      "<tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "run and create fresh results whenever the `GenericFunction` is called.\n",
      "\n",
      "## Features\n",
      "\n",
      "`func` may use data-dependent Python control flow statements, including `if`,\n",
      "`for`, `while` `break`, `continue` and `return`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   if tf.reduce_sum(x) > 0:\n",
      "...     return x * x\n",
      "...   else:\n",
      "...     return -x // 2\n",
      ">>> f(tf.constant(-2))\n",
      "<tf.Tensor: ... numpy=1>\n",
      "\n",
      "`func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f():\n",
      "...   return x ** 2 + y\n",
      ">>> x = tf.constant([-2, -3])\n",
      ">>> y = tf.Variable([3, -2])\n",
      ">>> f()\n",
      "<tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "`func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "and others:\n",
      "\n",
      ">>> v = tf.Variable(1)\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   for i in tf.range(x):\n",
      "...     v.assign_add(i)\n",
      ">>> f(3)\n",
      ">>> v\n",
      "<tf.Variable ... numpy=4>\n",
      "\n",
      "Important: Any Python side-effects (appending to a list, printing with\n",
      "`print`, etc) will only happen once, when `func` is traced. To have\n",
      "side-effects executed into your `tf.function` they need to be written\n",
      "as TF ops:\n",
      "\n",
      ">>> l = []\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   for i in x:\n",
      "...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      ">>> f(tf.constant([1, 2, 3]))\n",
      ">>> l\n",
      "[<tf.Tensor ...>]\n",
      "\n",
      "Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "...   for i in range(len(x)):\n",
      "...     ta = ta.write(i, x[i] + 1)\n",
      "...   return ta.stack()\n",
      ">>> f(tf.constant([1, 2, 3]))\n",
      "<tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "\n",
      "## `tf.function` creates polymorphic callables\n",
      "\n",
      "Internally, `tf.types.experimental.GenericFunction` may contain multiple\n",
      "`tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "different data types or shapes, since TensorFlow can perform more\n",
      "optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "each set of Python arguments that it encounters.\n",
      "For more information, see the\n",
      "[tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "\n",
      "Executing a `GenericFunction` will select and execute the appropriate\n",
      "`ConcreteFunction` based on the argument types and values.\n",
      "\n",
      "To obtain an individual `ConcreteFunction`, use the\n",
      "`GenericFunction.get_concrete_function` method. It can be called with the\n",
      "same arguments as `func` and returns a\n",
      "`tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "single `tf.Graph`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "True\n",
      "\n",
      "`ConcreteFunction`s can be executed just like `GenericFunction`s, but their\n",
      "input is resticted to the types to which they're specialized.\n",
      "\n",
      "## Retracing\n",
      "\n",
      "`ConcreteFunctions` are built (traced) on the fly, as the `GenericFunction` is\n",
      "called with new TensorFlow types or shapes, or with new Python values as\n",
      "arguments. When `GenericFunction` builds a new trace, it is said that `func`\n",
      "is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "it can be considerably slower than executing a graph that's already been\n",
      "traced. It is ideal to minimize the amount of retracing in your code.\n",
      "\n",
      "Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "possible:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return tf.abs(x)\n",
      ">>> f1 = f.get_concrete_function(1)\n",
      ">>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      ">>> f1 is f2\n",
      "False\n",
      ">>> f1 = f.get_concrete_function(tf.constant(1))\n",
      ">>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      ">>> f1 is f2\n",
      "True\n",
      "\n",
      "Python numerical arguments should only be used when they take few distinct\n",
      "values, such as hyperparameters like the number of layers in a neural network.\n",
      "\n",
      "## Input signatures\n",
      "\n",
      "For Tensor arguments, `GenericFunction`creates a new `ConcreteFunction` for\n",
      "every unique set of input shapes and datatypes. The example below creates two\n",
      "separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> vector = tf.constant([1.0, 1.0])\n",
      ">>> matrix = tf.constant([[3.0]])\n",
      ">>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "False\n",
      "\n",
      "An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "this process. The input signature specifies the shape and type of each\n",
      "Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "restricts the `GenericFunction` to the specified shapes and types. It is\n",
      "an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "\n",
      ">>> @tf.function(\n",
      "...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> vector = tf.constant([1.0, 1.0])\n",
      ">>> matrix = tf.constant([[3.0]])\n",
      ">>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "True\n",
      "\n",
      "## Variables may only be created once\n",
      "\n",
      "`tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "for the first time:\n",
      "\n",
      ">>> class MyModule(tf.Module):\n",
      "...   def __init__(self):\n",
      "...     self.v = None\n",
      "...\n",
      "...   @tf.function\n",
      "...   def __call__(self, x):\n",
      "...     if self.v is None:\n",
      "...       self.v = tf.Variable(tf.ones_like(x))\n",
      "...     return self.v * x\n",
      "\n",
      "In general, it is recommended to create `tf.Variable`s outside of\n",
      "`tf.function`.\n",
      "In simple cases, persisting state across `tf.function` boundaries may be\n",
      "implemented using a pure functional style in which state is represented by\n",
      "`tf.Tensor`s passed as arguments and returned as return values.\n",
      "\n",
      "Contrast the two styles below:\n",
      "\n",
      ">>> state = tf.Variable(1)\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   state.assign_add(x)\n",
      ">>> f(tf.constant(2))  # Non-pure functional style\n",
      ">>> state\n",
      "<tf.Variable ... numpy=3>\n",
      "\n",
      ">>> state = tf.constant(1)\n",
      ">>> @tf.function\n",
      "... def f(state, x):\n",
      "...   state += x\n",
      "...   return state\n",
      ">>> state = f(state, tf.constant(2))  # Pure functional style\n",
      ">>> state\n",
      "<tf.Tensor: ... numpy=3>\n",
      "\n",
      "## Python operations execute only once per trace\n",
      "\n",
      "`func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "However, when the function is executed, only the TensorFlow operations will\n",
      "run. The Python operations run only once, at trace time. If TensorFlow\n",
      "operations depend on results from Python operations, those results will be\n",
      "frozen into the graph.\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(a, b):\n",
      "...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "...   return b\n",
      ">>> f(1, tf.constant(1))\n",
      "this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      ">>> f(1, tf.constant(2))\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      ">>> f(2, tf.constant(1))\n",
      "this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      ">>> f(2, tf.constant(2))\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "## Using type annotations to improve performance\n",
      "\n",
      "`experimental_follow_type_hints` can be used along with type annotations to\n",
      "reduce retracing by automatically casting any Python values to `tf.Tensor`\n",
      "(something that is not done by default, unless you use input signatures).\n",
      "\n",
      ">>> @tf.function(experimental_follow_type_hints=True)\n",
      "... def f_with_hints(x: tf.Tensor):\n",
      "...   print('Tracing')\n",
      "...   return x\n",
      ">>> @tf.function(experimental_follow_type_hints=False)\n",
      "... def f_no_hints(x: tf.Tensor):\n",
      "...   print('Tracing')\n",
      "...   return x\n",
      ">>> f_no_hints(1)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      ">>> f_no_hints(2)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      ">>> f_with_hints(1)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      ">>> f_with_hints(2)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "Args:\n",
      "  func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "    a decorator that can be invoked with a single argument - `func`. In other\n",
      "    words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "    `tf.function(func, input_signature=...)`. The former can be used as\n",
      "    decorator.\n",
      "  input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "    specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "    this function. If `None`, a separate function is instantiated for each\n",
      "    inferred input signature.  If input_signature is specified, every input to\n",
      "    `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "  autograph: Whether autograph should be applied on `func` before tracing a\n",
      "    graph. Data-dependent Python control flow statements require\n",
      "    `autograph=True`. For more information, see the\n",
      "    [tf.function and AutoGraph guide](\n",
      "    https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "  jit_compile: If `True`, compiles the function using\n",
      "    [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "    such as fusion, and attempts to emit more efficient code. This may\n",
      "    drastically improve the performance. If set to `True`,\n",
      "    the whole function needs to be compilable by XLA, or an\n",
      "    `errors.InvalidArgumentError` is thrown.\n",
      "    If `None` (default), compiles the function with XLA when running on TPU\n",
      "    and goes through the regular function execution path when running on\n",
      "    other devices.\n",
      "    If `False`, executes the function without XLA compilation.  Set this value\n",
      "    to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "    TPU cores, one TPU core and its host CPU).\n",
      "    Not all functions are compilable, see a list of\n",
      "    [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "  reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "    amount of retracing, for example by using more generic shapes. This\n",
      "    can be controlled for user objects by customizing their associated\n",
      "    `tf.types.experimental.TraceType`.\n",
      "  experimental_implements: If provided, contains a name of a \"known\" function\n",
      "    this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "    This is stored as an attribute in inference function,\n",
      "    which can then be detected when processing serialized function.\n",
      "    See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "    for details.  For an example of utilizing this attribute see this\n",
      "    [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "    The code above automatically detects and substitutes function that\n",
      "    implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "    implementations. For instance, a tensorflow user can use this\n",
      "     attribute to mark that their function also implements\n",
      "    `embedded_matmul` (perhaps more efficiently!)\n",
      "    by specifying it using this parameter:\n",
      "    `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "    This can either be specified as just the string name of the function or\n",
      "    a NameAttrList corresponding to a list of key-value attributes associated\n",
      "    with the function name. The name of the function will be in the 'name'\n",
      "    field of the NameAttrList. To define a formal TF op for this function\n",
      "    implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "    project.\n",
      "  experimental_autograph_options: Optional tuple of\n",
      "    `tf.autograph.experimental.Feature` values.\n",
      "  experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "    instead.\n",
      "  experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "  experimental_follow_type_hints: When True, the function may use type\n",
      "    annotations from `func` to optimize the tracing performance. For example,\n",
      "    arguments annotated with `tf.Tensor` will automatically be converted\n",
      "    to a Tensor.\n",
      "\n",
      "Returns:\n",
      "   If `func` is not None, returns a `tf.types.experimental.GenericFunction`.\n",
      "   If `func` is None, returns a decorator that, when invoked with a single\n",
      "   `func` argument, returns a `tf.types.experimental.GenericFunction`.\n",
      "\n",
      "Raises:\n",
      "   `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "   not available.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "tf.function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def foo():\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.eager.def_function.Function"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=foo.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.eager.function.ConcreteFunction"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<contextlib._GeneratorContextManager object at 0x7fdef31e5f70>\n"
     ]
    }
   ],
   "source": [
    "print(g1.as_default())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.eager.function.Function"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(F1(f,\"asf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        module\n",
      "\u001b[0;31mString form:\u001b[0m <module 'tensorflow.python.eager.function' from '/home/taosy/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py'>\n",
      "\u001b[0;31mFile:\u001b[0m        ~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\n",
      "\u001b[0;31mDocstring:\u001b[0m   Defun decorator for defining graph-mode functions.\n"
     ]
    }
   ],
   "source": [
    "f1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_signature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mjit_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreduce_retracing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_implements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_autograph_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_relax_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_compile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexperimental_follow_type_hints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)\n",
      "\n",
      "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_compile)`. They will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_compile is deprecated, use jit_compile instead\n",
      "\n",
      "Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(experimental_relax_shapes)`. They will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "\n",
      "`tf.function` constructs a `tf.types.experimental.GenericFunction` that\n",
      "executes a TensorFlow graph (`tf.Graph`) created by trace-compiling the\n",
      "TensorFlow operations in `func`. More information on the topic can be found\n",
      "in [Introduction to Graphs and tf.function]\n",
      "(https://www.tensorflow.org/guide/intro_to_graphs).\n",
      "\n",
      "See [Better Performance with tf.function]\n",
      "(https://www.tensorflow.org/guide/function) for tips on performance and\n",
      "known limitations.\n",
      "\n",
      "Example usage:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x, y):\n",
      "...   return x ** 2 + y\n",
      ">>> x = tf.constant([2, 3])\n",
      ">>> y = tf.constant([3, -2])\n",
      ">>> f(x, y)\n",
      "<tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "The trace-compilation allows non-TensorFlow operations to execute, but under\n",
      "special conditions. In general, only TensorFlow operations are guaranteed to\n",
      "run and create fresh results whenever the `GenericFunction` is called.\n",
      "\n",
      "## Features\n",
      "\n",
      "`func` may use data-dependent Python control flow statements, including `if`,\n",
      "`for`, `while` `break`, `continue` and `return`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   if tf.reduce_sum(x) > 0:\n",
      "...     return x * x\n",
      "...   else:\n",
      "...     return -x // 2\n",
      ">>> f(tf.constant(-2))\n",
      "<tf.Tensor: ... numpy=1>\n",
      "\n",
      "`func`'s closure may include `tf.Tensor` and `tf.Variable` objects:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f():\n",
      "...   return x ** 2 + y\n",
      ">>> x = tf.constant([-2, -3])\n",
      ">>> y = tf.Variable([3, -2])\n",
      ">>> f()\n",
      "<tf.Tensor: ... numpy=array([7, 7], ...)>\n",
      "\n",
      "`func` may also use ops with side effects, such as `tf.print`, `tf.Variable`\n",
      "and others:\n",
      "\n",
      ">>> v = tf.Variable(1)\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   for i in tf.range(x):\n",
      "...     v.assign_add(i)\n",
      ">>> f(3)\n",
      ">>> v\n",
      "<tf.Variable ... numpy=4>\n",
      "\n",
      "Important: Any Python side-effects (appending to a list, printing with\n",
      "`print`, etc) will only happen once, when `func` is traced. To have\n",
      "side-effects executed into your `tf.function` they need to be written\n",
      "as TF ops:\n",
      "\n",
      ">>> l = []\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   for i in x:\n",
      "...     l.append(i + 1)    # Caution! Will only happen once when tracing\n",
      ">>> f(tf.constant([1, 2, 3]))\n",
      ">>> l\n",
      "[<tf.Tensor ...>]\n",
      "\n",
      "Instead, use TensorFlow collections like `tf.TensorArray`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   ta = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
      "...   for i in range(len(x)):\n",
      "...     ta = ta.write(i, x[i] + 1)\n",
      "...   return ta.stack()\n",
      ">>> f(tf.constant([1, 2, 3]))\n",
      "<tf.Tensor: ..., numpy=array([2, 3, 4], ...)>\n",
      "\n",
      "## `tf.function` creates polymorphic callables\n",
      "\n",
      "Internally, `tf.types.experimental.GenericFunction` may contain multiple\n",
      "`tf.types.experimental.ConcreteFunction`s, each specialized to arguments with\n",
      "different data types or shapes, since TensorFlow can perform more\n",
      "optimizations on graphs of specific shapes, dtypes and values of constant\n",
      "arguments. `tf.function` treats any pure Python values as opaque objects (best\n",
      "thought of as compile-time constants), and builds a separate `tf.Graph` for\n",
      "each set of Python arguments that it encounters.\n",
      "For more information, see the\n",
      "[tf.function guide](https://www.tensorflow.org/guide/function#rules_of_tracing)\n",
      "\n",
      "Executing a `GenericFunction` will select and execute the appropriate\n",
      "`ConcreteFunction` based on the argument types and values.\n",
      "\n",
      "To obtain an individual `ConcreteFunction`, use the\n",
      "`GenericFunction.get_concrete_function` method. It can be called with the\n",
      "same arguments as `func` and returns a\n",
      "`tf.types.experimental.ConcreteFunction`. `ConcreteFunction`s are backed by a\n",
      "single `tf.Graph`:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> isinstance(f.get_concrete_function(1).graph, tf.Graph)\n",
      "True\n",
      "\n",
      "`ConcreteFunction`s can be executed just like `GenericFunction`s, but their\n",
      "input is resticted to the types to which they're specialized.\n",
      "\n",
      "## Retracing\n",
      "\n",
      "`ConcreteFunctions` are built (traced) on the fly, as the `GenericFunction` is\n",
      "called with new TensorFlow types or shapes, or with new Python values as\n",
      "arguments. When `GenericFunction` builds a new trace, it is said that `func`\n",
      "is retraced. Retracing is a frequent performance concern for `tf.function` as\n",
      "it can be considerably slower than executing a graph that's already been\n",
      "traced. It is ideal to minimize the amount of retracing in your code.\n",
      "\n",
      "Caution: Passing python scalars or lists as arguments to `tf.function` will\n",
      "usually retrace. To avoid this, pass numeric arguments as Tensors whenever\n",
      "possible:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return tf.abs(x)\n",
      ">>> f1 = f.get_concrete_function(1)\n",
      ">>> f2 = f.get_concrete_function(2)  # Slow - compiles new graph\n",
      ">>> f1 is f2\n",
      "False\n",
      ">>> f1 = f.get_concrete_function(tf.constant(1))\n",
      ">>> f2 = f.get_concrete_function(tf.constant(2))  # Fast - reuses f1\n",
      ">>> f1 is f2\n",
      "True\n",
      "\n",
      "Python numerical arguments should only be used when they take few distinct\n",
      "values, such as hyperparameters like the number of layers in a neural network.\n",
      "\n",
      "## Input signatures\n",
      "\n",
      "For Tensor arguments, `GenericFunction`creates a new `ConcreteFunction` for\n",
      "every unique set of input shapes and datatypes. The example below creates two\n",
      "separate `ConcreteFunction`s, each specialized to a different shape:\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> vector = tf.constant([1.0, 1.0])\n",
      ">>> matrix = tf.constant([[3.0]])\n",
      ">>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "False\n",
      "\n",
      "An \"input signature\" can be optionally provided to `tf.function` to control\n",
      "this process. The input signature specifies the shape and type of each\n",
      "Tensor argument to the function using a `tf.TensorSpec` object. More general\n",
      "shapes can be used. This ensures only one `ConcreteFunction` is created, and\n",
      "restricts the `GenericFunction` to the specified shapes and types. It is\n",
      "an effective way to limit retracing when Tensors have dynamic shapes.\n",
      "\n",
      ">>> @tf.function(\n",
      "...     input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "... def f(x):\n",
      "...   return x + 1\n",
      ">>> vector = tf.constant([1.0, 1.0])\n",
      ">>> matrix = tf.constant([[3.0]])\n",
      ">>> f.get_concrete_function(vector) is f.get_concrete_function(matrix)\n",
      "True\n",
      "\n",
      "## Variables may only be created once\n",
      "\n",
      "`tf.function` only allows creating new `tf.Variable` objects when it is called\n",
      "for the first time:\n",
      "\n",
      ">>> class MyModule(tf.Module):\n",
      "...   def __init__(self):\n",
      "...     self.v = None\n",
      "...\n",
      "...   @tf.function\n",
      "...   def __call__(self, x):\n",
      "...     if self.v is None:\n",
      "...       self.v = tf.Variable(tf.ones_like(x))\n",
      "...     return self.v * x\n",
      "\n",
      "In general, it is recommended to create `tf.Variable`s outside of\n",
      "`tf.function`.\n",
      "In simple cases, persisting state across `tf.function` boundaries may be\n",
      "implemented using a pure functional style in which state is represented by\n",
      "`tf.Tensor`s passed as arguments and returned as return values.\n",
      "\n",
      "Contrast the two styles below:\n",
      "\n",
      ">>> state = tf.Variable(1)\n",
      ">>> @tf.function\n",
      "... def f(x):\n",
      "...   state.assign_add(x)\n",
      ">>> f(tf.constant(2))  # Non-pure functional style\n",
      ">>> state\n",
      "<tf.Variable ... numpy=3>\n",
      "\n",
      ">>> state = tf.constant(1)\n",
      ">>> @tf.function\n",
      "... def f(state, x):\n",
      "...   state += x\n",
      "...   return state\n",
      ">>> state = f(state, tf.constant(2))  # Pure functional style\n",
      ">>> state\n",
      "<tf.Tensor: ... numpy=3>\n",
      "\n",
      "## Python operations execute only once per trace\n",
      "\n",
      "`func` may contain TensorFlow operations mixed with pure Python operations.\n",
      "However, when the function is executed, only the TensorFlow operations will\n",
      "run. The Python operations run only once, at trace time. If TensorFlow\n",
      "operations depend on results from Python operations, those results will be\n",
      "frozen into the graph.\n",
      "\n",
      ">>> @tf.function\n",
      "... def f(a, b):\n",
      "...   print('this runs at trace time; a is', a, 'and b is', b)\n",
      "...   return b\n",
      ">>> f(1, tf.constant(1))\n",
      "this runs at trace time; a is 1 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      ">>> f(1, tf.constant(2))\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      ">>> f(2, tf.constant(1))\n",
      "this runs at trace time; a is 2 and b is Tensor(\"...\", shape=(), dtype=int32)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      "\n",
      ">>> f(2, tf.constant(2))\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "## Using type annotations to improve performance\n",
      "\n",
      "`experimental_follow_type_hints` can be used along with type annotations to\n",
      "reduce retracing by automatically casting any Python values to `tf.Tensor`\n",
      "(something that is not done by default, unless you use input signatures).\n",
      "\n",
      ">>> @tf.function(experimental_follow_type_hints=True)\n",
      "... def f_with_hints(x: tf.Tensor):\n",
      "...   print('Tracing')\n",
      "...   return x\n",
      ">>> @tf.function(experimental_follow_type_hints=False)\n",
      "... def f_no_hints(x: tf.Tensor):\n",
      "...   print('Tracing')\n",
      "...   return x\n",
      ">>> f_no_hints(1)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      ">>> f_no_hints(2)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      ">>> f_with_hints(1)\n",
      "Tracing\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
      ">>> f_with_hints(2)\n",
      "<tf.Tensor: shape=(), dtype=int32, numpy=2>\n",
      "\n",
      "Args:\n",
      "  func: The function to be compiled. If `func` is None, `tf.function` returns\n",
      "    a decorator that can be invoked with a single argument - `func`. In other\n",
      "    words, `tf.function(input_signature=...)(func)` is equivalent to\n",
      "    `tf.function(func, input_signature=...)`. The former can be used as\n",
      "    decorator.\n",
      "  input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "    specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "    this function. If `None`, a separate function is instantiated for each\n",
      "    inferred input signature.  If input_signature is specified, every input to\n",
      "    `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "  autograph: Whether autograph should be applied on `func` before tracing a\n",
      "    graph. Data-dependent Python control flow statements require\n",
      "    `autograph=True`. For more information, see the\n",
      "    [tf.function and AutoGraph guide](\n",
      "    https://www.tensorflow.org/guide/function#autograph_transformations).\n",
      "  jit_compile: If `True`, compiles the function using\n",
      "    [XLA](https://tensorflow.org/xla). XLA performs compiler optimizations,\n",
      "    such as fusion, and attempts to emit more efficient code. This may\n",
      "    drastically improve the performance. If set to `True`,\n",
      "    the whole function needs to be compilable by XLA, or an\n",
      "    `errors.InvalidArgumentError` is thrown.\n",
      "    If `None` (default), compiles the function with XLA when running on TPU\n",
      "    and goes through the regular function execution path when running on\n",
      "    other devices.\n",
      "    If `False`, executes the function without XLA compilation.  Set this value\n",
      "    to `False` when directly running a multi-device function on TPUs (e.g. two\n",
      "    TPU cores, one TPU core and its host CPU).\n",
      "    Not all functions are compilable, see a list of\n",
      "    [sharp corners](https://tensorflow.org/xla/known_issues).\n",
      "  reduce_retracing: When True, `tf.function` attempts to reduce the\n",
      "    amount of retracing, for example by using more generic shapes. This\n",
      "    can be controlled for user objects by customizing their associated\n",
      "    `tf.types.experimental.TraceType`.\n",
      "  experimental_implements: If provided, contains a name of a \"known\" function\n",
      "    this implements. For example \"mycompany.my_recurrent_cell\".\n",
      "    This is stored as an attribute in inference function,\n",
      "    which can then be detected when processing serialized function.\n",
      "    See [standardizing composite ops](https://github.com/tensorflow/community/blob/master/rfcs/20190610-standardizing-composite_ops.md)  # pylint: disable=line-too-long\n",
      "    for details.  For an example of utilizing this attribute see this\n",
      "    [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/prepare_composite_functions_tf.cc)\n",
      "    The code above automatically detects and substitutes function that\n",
      "    implements \"embedded_matmul\" and allows TFLite to substitute its own\n",
      "    implementations. For instance, a tensorflow user can use this\n",
      "     attribute to mark that their function also implements\n",
      "    `embedded_matmul` (perhaps more efficiently!)\n",
      "    by specifying it using this parameter:\n",
      "    `@tf.function(experimental_implements=\"embedded_matmul\")`\n",
      "    This can either be specified as just the string name of the function or\n",
      "    a NameAttrList corresponding to a list of key-value attributes associated\n",
      "    with the function name. The name of the function will be in the 'name'\n",
      "    field of the NameAttrList. To define a formal TF op for this function\n",
      "    implements, try the experimental [composite TF](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tfr)\n",
      "    project.\n",
      "  experimental_autograph_options: Optional tuple of\n",
      "    `tf.autograph.experimental.Feature` values.\n",
      "  experimental_relax_shapes: Deprecated. Use `reduce_retracing`\n",
      "    instead.\n",
      "  experimental_compile: Deprecated alias to 'jit_compile'.\n",
      "  experimental_follow_type_hints: When True, the function may use type\n",
      "    annotations from `func` to optimize the tracing performance. For example,\n",
      "    arguments annotated with `tf.Tensor` will automatically be converted\n",
      "    to a Tensor.\n",
      "\n",
      "Returns:\n",
      "   If `func` is not None, returns a `tf.types.experimental.GenericFunction`.\n",
      "   If `func` is None, returns a decorator that, when invoked with a single\n",
      "   `func` argument, returns a `tf.types.experimental.GenericFunction`.\n",
      "\n",
      "Raises:\n",
      "   `ValueError` when attempting to use `jit_compile=True`, but XLA support is\n",
      "   not available.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "f2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager.def_function import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: tf__my_func() missing 2 required positional arguments: 'x' and 'y'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[39m.\u001b[39;49mget_concrete_function()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:1239\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1238\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1240\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:1219\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1219\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1220\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1223\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2667\u001b[0m ]\n\u001b[1;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2673\u001b[0m         args,\n\u001b[1;32m   2674\u001b[0m         kwargs,\n\u001b[1;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__my_func() missing 2 required positional arguments: 'x' and 'y'\n"
     ]
    }
   ],
   "source": [
    "a.get_concrete_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
